{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0e0b8-fb1f-4437-9815-3899575173d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel, GPT2Tokenizer, GPT2LMHeadModel\n",
    "import requests\n",
    "\n",
    "# CLIP 모델 및 프로세서 로드\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "# GPT-2 모델 및 토크나이저 로드\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# 이미지 로드 및 전처리\n",
    "def load_image(image_path=None, url=None):\n",
    "    if url:\n",
    "        # URL에서 이미지 로드\n",
    "        image = Image.open(requests.get(url, stream=True).raw)\n",
    "    elif image_path:\n",
    "        # 로컬 경로에서 이미지 로드\n",
    "        image = Image.open(image_path)\n",
    "    else:\n",
    "        raise ValueError(\"Image path or URL must be provided.\")\n",
    "    return image\n",
    "\n",
    "# 이미지에서 특징 추출\n",
    "def extract_image_features(image_path=None, url=None):\n",
    "    image = load_image(image_path=image_path, url=url)\n",
    "    inputs = clip_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        image_features = clip_model.get_image_features(**inputs)\n",
    "    return image_features\n",
    "\n",
    "# 이미지 특징과 가장 유사한 텍스트 생성\n",
    "def find_similar_text(image_features, candidate_texts):\n",
    "    inputs = clip_processor(text=candidate_texts, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_features = clip_model.get_text_features(**inputs)\n",
    "\n",
    "    # 이미지 특징과 텍스트 특징 간의 유사도를 계산\n",
    "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = torch.matmul(image_features, text_features.T)\n",
    "\n",
    "    # 가장 유사한 텍스트를 선택\n",
    "    best_match_index = similarity.argmax().item()\n",
    "    return candidate_texts[best_match_index]\n",
    "\n",
    "# 이미지 특징을 기반으로 캡션 생성\n",
    "def generate_caption_from_image(image_path=None, url=None):\n",
    "    # 이미지에서 특징 추출\n",
    "    image_features = extract_image_features(image_path=image_path, url=url)\n",
    "\n",
    "    # CLIP 모델로부터 텍스트 후보군 생성 (캡션 후보)\n",
    "    candidate_texts = [\n",
    "        \"A photo of a cat\",\n",
    "        \"A picture of a dog\",\n",
    "        \"A landscape with mountains\",\n",
    "        \"A person riding a horse\",\n",
    "        \"An aerial view of a city\",\n",
    "        \"A close-up shot of food\",\n",
    "    ]\n",
    "\n",
    "    # 이미지 특징과 가장 유사한 텍스트 찾기\n",
    "    best_caption = find_similar_text(image_features, candidate_texts)\n",
    "\n",
    "    # GPT-2 모델을 사용하여 이미지 특징 기반으로 캡션 확장\n",
    "    input_ids = gpt2_tokenizer.encode(best_caption, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = gpt2_model.generate(input_ids, max_length=30, num_return_sequences=1,\n",
    "                                       num_beams=5, early_stopping=True)\n",
    "\n",
    "    generated_caption = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_caption\n",
    "\n",
    "# 예시 이미지 경로 또는 URL\n",
    "image_path = \"path/to/your/image.jpg\"  # 로컬 이미지 경로\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"  # URL 이미지\n",
    "\n",
    "# 캡션 생성\n",
    "generated_caption = generate_caption_from_image(url=url)  # 또는 image_path=image_path\n",
    "print(\"Generated Caption:\", generated_caption)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

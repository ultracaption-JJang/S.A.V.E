{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ae8b11-d45b-4610-9af1-b27b7b9867cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from torch.quantization import quantize_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c7b51e-6a6d-41ab-9aa2-b5a642aff54a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843c7df2-e468-4a3f-b336-59445445a2c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97082cd4-5e19-46af-9fda-5c07a10a6c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # 필요한 만큼만 메모리를 사용하도록 설정\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            \n",
    "        # 특정 GPU에 연산을 할당\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        \n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8e1ea5-81fb-4556-beb8-a21e1a3a3a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"yolo_quan_local.ipynb\"  # 노트북 이름을 설정하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca96b86-36d3-4d95-95b8-51645f702c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\희정\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# WandB에 로그인\n",
    "wandb.login(key='debec7acbfa814ac1d35013a84ac13808d992cd0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b0cf46-f2cc-4c15-86df-4598863b4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sweep 구성설정\n",
    "# sweep_config = {\n",
    "#     'name': 'yolo_sweep',\n",
    "#     'method': 'random',  # 또는 \"grid\"를 사용할 수 있습니다.\n",
    "#     'metric': {'name': 'val_map50', 'goal': 'maximize'},\n",
    "#     'parameters': {\n",
    "#         'batch_size': {'values': [16, 32, 64]},\n",
    "#         'learning_rate': {'min': 1e-5, 'max': 1e-2},\n",
    "#         'epochs': {'values': [10, 20, 30, 40, 50]}\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# wandb Sweep 설정 - 최적화할 metric을 box_loss로 설정\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",  # Bayesian optimization으로 하이퍼파라미터 탐색\n",
    "    \"metric\": {\"name\": \"box_loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"lr\": {\"values\": [0.001, 0.0005, 0.0001]},\n",
    "        \"epochs\": {\"values\": [10, 20]},\n",
    "        \"batch_size\": {\"values\": [16, 32]},\n",
    "        \"patience\": {\"value\": 3}  # Early stopping을 위한 patience 추가\n",
    "    },\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"yolo11-quantization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94cfc9c3-8f51-44ec-9afd-00849a611212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: r4oeedyv\n",
      "Sweep URL: https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv\n"
     ]
    }
   ],
   "source": [
    "# # Sweep ID 생성\n",
    "# sweep_id = wandb.sweep(sweep_config, project=\"yolo11-quantization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8017083-126f-41f4-b9b8-75d16ca9c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # WandB 초기화\n",
    "    wandb.init(project=\"yolo11-quantization\", entity=\"icejoy000524-student\")\n",
    "\n",
    "    # wandb Sweep으로 설정된 하이퍼파라미터 불러오기\n",
    "    config = wandb.config\n",
    "    learning_rate = config.lr\n",
    "    epochs = config.epochs\n",
    "    batch_size = config.batch_size\n",
    "    patience = config.patience  # Early stopping을 위한 patience 불러오기\n",
    "\n",
    "    # YOLOv11 모델 로드\n",
    "    model = YOLO(\"yolo11n.pt\")  # YOLOv11 모델 가중치 파일 경로\n",
    "\n",
    "    best_mAP = 0\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # 훈련 설정\n",
    "    results = model.train(\n",
    "        data=\"C:/Users/희정/NIPAPROJECT/yolodata/yolo_split/yolo.yaml\",  # 데이터셋 YAML 파일 경로\n",
    "        epochs=epochs,  # Sweep에서 정의한 에폭 수\n",
    "        imgsz=640,  # 이미지 크기\n",
    "        batch=batch_size,  # Sweep에서 정의한 배치 사이즈\n",
    "        lr0=learning_rate,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",  # 사용 가능한 장치\n",
    "    )\n",
    "\n",
    "    # box_loss와 다른 메트릭을 로깅하여 wandb에 기록\n",
    "    for epoch, metrics in enumerate(results):\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"mAP_0.5\": metrics[\"metrics/mAP_0.5\"],\n",
    "            \"box_loss\": metrics[\"loss/box\"],  # 최적화할 손실 메트릭\n",
    "            \"obj_loss\": metrics[\"loss/obj\"],\n",
    "            \"cls_loss\": metrics[\"loss/cls\"],\n",
    "        })\n",
    "\n",
    "        # Early Stopping 로직\n",
    "        current_mAP = metrics[\"metrics/mAP_0.5\"]\n",
    "        if current_mAP > best_mAP:\n",
    "            best_mAP = current_mAP\n",
    "            epochs_without_improvement = 0  # 개선이 있었으므로 카운트 초기화\n",
    "            wandb.log({\"best_mAP\": best_mAP})  # 최상의 mAP 기록\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "        \n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break  # 조기 중단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9528248-497a-45e2-a7a2-cd1d8bd1d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: z80ngibh with config:\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tlearning_rate: 0.008071457081693233\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\희정\\NIPAPROJECT\\wandb\\run-20241031_203428-z80ngibh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/z80ngibh' target=\"_blank\">eager-sweep-7</a></strong> to <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/z80ngibh' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/z80ngibh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:/Users//NIPAPROJECT/yolodata/yolo_split/yolo.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train4\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 755k/755k [00:00<00:00, 11.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    435352  ultralytics.nn.modules.head.Detect           [24, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,594,520 parameters, 2,594,504 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train4', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train...:   0%|          | 0/752 [00:00<?, ?it/s]Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train... 89 images, 0 backgrounds, 0 corrupt:  12%|█▏    Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train... 220 images, 0 backgrounds, 0 corrupt:  29%|██▉  Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train... 351 images, 0 backgrounds, 0 corrupt:  47%|████▋Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train... 485 images, 0 backgrounds, 0 corrupt:  64%|█████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train... 615 images, 0 backgrounds, 0 corrupt:  82%|█████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train... 746 images, 0 backgrounds, 0 corrupt:  99%|█████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train... 752 images, 0 backgrounds, 0 corrupt: 100%|█████\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\train\\MP_SEL_000231.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val...:   0%|          | 0/94 [00:00<?, ?it/s]Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val... 94 images, 0 backgrounds, 0 corrupt: 100%|██████████\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache\n",
      "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000357, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.729      4.446      1.319        128        640: 100%|██████████| 47/47 [03:35<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0493     0.0167     0.0324     0.0286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.712      3.528      1.281        166        640: 100%|██████████| 47/47 [03:22<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.87     0.0345     0.0573     0.0377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.659       2.85      1.262        124        640: 100%|██████████| 47/47 [03:19<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.781     0.0864     0.0864     0.0455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.622      2.423      1.236        155        640: 100%|██████████| 47/47 [03:08<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.611       0.12      0.115     0.0592\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.575      2.235      1.223        126        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.53      0.182      0.135     0.0755\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.541      2.073      1.222        140        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.545       0.18      0.147     0.0822\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      1.508      1.962      1.202        128        640: 100%|██████████| 47/47 [03:01<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.622      0.168      0.156     0.0901\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G      1.474      1.885      1.181        154        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.698      0.171      0.178      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G      1.465      1.848      1.176        127        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.675      0.175      0.172     0.0982\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      1.414       1.79      1.159        191        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.685      0.176      0.185      0.109\n",
      "\n",
      "10 epochs completed in 0.544 hours.\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train4\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train4\\weights\\best.pt...\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.685      0.177      0.185      0.109\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.665      0.808       0.82      0.585\n",
      "          potted_plant          9         26      0.361      0.154      0.131      0.064\n",
      "          fire_hydrant          3          4          1          0     0.0135    0.00867\n",
      "       movable_signage         14         27      0.494      0.222      0.244      0.169\n",
      "            motorcycle          4          4      0.211       0.25      0.277      0.188\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0      0.024     0.0115\n",
      "               bicycle          4          7      0.265      0.286      0.316        0.1\n",
      "          traffic_sign         16         27          1     0.0989      0.133     0.0806\n",
      "             barricade          2          2          1          0          0          0\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121      0.531      0.393      0.403      0.196\n",
      "                person         33         65      0.557      0.338       0.35      0.194\n",
      "                  pole         70        145      0.639      0.366      0.491      0.223\n",
      "                  stop          2          2          1          0          0          0\n",
      "                 chair          5          7      0.448      0.143       0.09      0.048\n",
      "         traffic_light          4         11          1          0     0.0087    0.00609\n",
      "                 truck         27         39      0.597      0.455      0.486      0.367\n",
      "               bollard         14         32      0.304      0.375      0.276      0.157\n",
      "Speed: 0.7ms preprocess, 28.6ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.685      0.177      0.185      0.109\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.665      0.808       0.82      0.585\n",
      "          potted_plant          9         26      0.361      0.154      0.131      0.064\n",
      "          fire_hydrant          3          4          1          0     0.0135    0.00867\n",
      "       movable_signage         14         27      0.494      0.222      0.244      0.169\n",
      "            motorcycle          4          4      0.211       0.25      0.277      0.188\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0      0.024     0.0115\n",
      "               bicycle          4          7      0.265      0.286      0.316        0.1\n",
      "          traffic_sign         16         27          1     0.0989      0.133     0.0806\n",
      "             barricade          2          2          1          0          0          0\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121      0.531      0.393      0.403      0.196\n",
      "                person         33         65      0.557      0.338       0.35      0.194\n",
      "                  pole         70        145      0.639      0.366      0.491      0.223\n",
      "                  stop          2          2          1          0          0          0\n",
      "                 chair          5          7      0.448      0.143       0.09      0.048\n",
      "         traffic_light          4         11          1          0     0.0087    0.00609\n",
      "                 truck         27         39      0.597      0.455      0.486      0.367\n",
      "               bollard         14         32      0.304      0.375      0.276      0.157\n",
      "Speed: 0.6ms preprocess, 27.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train42\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_size</td><td>▁</td></tr><tr><td>val_fitness</td><td>▁</td></tr><tr><td>val_map</td><td>▁</td></tr><tr><td>val_map50</td><td>▁</td></tr><tr><td>val_map50_95</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_path</td><td>yolo11_quantized.pt</td></tr><tr><td>quantized_model_size</td><td>2586832</td></tr><tr><td>val_fitness</td><td>0.11651</td></tr><tr><td>val_map</td><td>0.10893</td></tr><tr><td>val_map50</td><td>0.1847</td></tr><tr><td>val_map50_95</td><td>0.10893</td></tr><tr><td>val_precision</td><td>0.68505</td></tr><tr><td>val_recall</td><td>0.17681</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-sweep-7</strong> at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/z80ngibh' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/z80ngibh</a><br/> View project at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241031_203428-z80ngibh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: 31chi6bc with config:\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tepochs: 30\n",
      "wandb: \tlearning_rate: 0.003702164157919323\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\희정\\NIPAPROJECT\\wandb\\run-20241031_210745-31chi6bc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/31chi6bc' target=\"_blank\">lyric-sweep-8</a></strong> to <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/31chi6bc' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/31chi6bc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:/Users//NIPAPROJECT/yolodata/yolo_split/yolo.yaml, epochs=30, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train5\n",
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    435352  ultralytics.nn.modules.head.Detect           [24, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,594,520 parameters, 2,594,504 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train5', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\train\\MP_SEL_000231.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train5\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000357, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train5\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30         0G       1.67      4.539      1.284        365        640: 100%|██████████| 24/24 [03:14<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30         0G      1.703       3.85      1.243        250        640: 100%|██████████| 24/24 [03:14<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0446     0.0437     0.0431     0.0323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30         0G      1.655      3.117      1.233        268        640: 100%|██████████| 24/24 [03:15<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0559      0.108     0.0741     0.0475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30         0G      1.644      2.609      1.227        195        640: 100%|██████████| 24/24 [03:12<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.789     0.0719      0.102     0.0594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30         0G      1.586      2.198      1.214        290        640: 100%|██████████| 24/24 [03:15<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.667     0.0841     0.0994     0.0551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30         0G      1.565      1.985      1.207        307        640: 100%|██████████| 24/24 [03:17<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.668      0.121      0.129     0.0753\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30         0G      1.561      1.873      1.211        345        640: 100%|██████████| 24/24 [03:15<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.673      0.139      0.156     0.0943\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30         0G      1.514      1.779      1.184        246        640: 100%|██████████| 24/24 [03:18<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.597      0.151      0.176     0.0957\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30         0G      1.454      1.693      1.173        320        640: 100%|██████████| 24/24 [03:17<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.719      0.169      0.179      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30         0G      1.435      1.616      1.154        272        640: 100%|██████████| 24/24 [03:15<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.681      0.161      0.177      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30         0G      1.458      1.598      1.161        250        640: 100%|██████████| 24/24 [03:16<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.609      0.158      0.185       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30         0G      1.411      1.546      1.144        268        640: 100%|██████████| 24/24 [03:15<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.596      0.175      0.194      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30         0G      1.412      1.542      1.138        353        640: 100%|██████████| 24/24 [03:15<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.703      0.148      0.195      0.109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30         0G      1.394      1.489      1.124        258        640: 100%|██████████| 24/24 [03:16<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.57       0.21      0.207       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30         0G      1.374      1.467      1.117        312        640: 100%|██████████| 24/24 [03:13<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.629      0.179      0.214      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30         0G      1.357      1.453      1.121        270        640: 100%|██████████| 24/24 [03:16<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.592      0.168      0.209       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30         0G      1.367      1.436      1.116        357        640: 100%|██████████| 24/24 [03:16<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.409      0.217      0.219      0.123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30         0G      1.336      1.405      1.107        196        640: 100%|██████████| 24/24 [03:17<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.569      0.214      0.217      0.115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30         0G      1.328      1.388      1.109        311        640: 100%|██████████| 24/24 [03:17<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.598      0.204      0.237      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30         0G      1.334      1.367      1.104        325        640: 100%|██████████| 24/24 [03:18<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.686      0.198      0.246      0.135\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30         0G      1.365      1.577      1.136        148        640: 100%|██████████| 24/24 [03:10<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.54      0.199      0.218      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30         0G      1.311      1.441      1.114        132        640: 100%|██████████| 24/24 [03:09<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.64      0.198      0.242      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30         0G      1.286      1.389      1.094        130        640: 100%|██████████| 24/24 [03:10<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.643        0.2       0.24      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30         0G      1.272      1.368      1.092        111        640: 100%|██████████| 24/24 [03:08<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.668      0.214      0.252      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30         0G      1.281       1.37      1.093        153        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.651      0.207      0.265      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30         0G      1.268      1.352      1.086        127        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.666      0.228       0.27      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30         0G      1.254      1.341      1.072        162        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.691      0.219       0.27       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30         0G      1.229      1.325      1.076        149        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.623       0.25      0.274      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30         0G      1.237      1.315       1.07        125        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.638      0.246      0.278      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30         0G      1.253      1.317      1.072        125        640: 100%|██████████| 24/24 [03:04<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.68      0.231      0.278      0.156\n",
      "\n",
      "30 epochs completed in 1.669 hours.\n",
      "Optimizer stripped from runs\\detect\\train5\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train5\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train5\\weights\\best.pt...\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.64      0.246      0.278      0.157\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261       0.66      0.826      0.859      0.631\n",
      "          potted_plant          9         26        0.3      0.192      0.204      0.105\n",
      "          fire_hydrant          3          4          1          0     0.0198    0.00593\n",
      "       movable_signage         14         27      0.355       0.37      0.329      0.201\n",
      "            motorcycle          4          4      0.561        0.5      0.423      0.227\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0      0.074     0.0474\n",
      "               bicycle          4          7      0.586      0.611      0.561      0.235\n",
      "          traffic_sign         16         27      0.434      0.111      0.192      0.104\n",
      "             barricade          2          2          1          0      0.166     0.0871\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0      0.181      0.134\n",
      "            tree_trunk         34        121      0.528      0.479      0.475      0.241\n",
      "                person         33         65      0.612      0.446      0.481      0.248\n",
      "                  pole         70        145      0.588      0.566      0.586      0.266\n",
      "                  stop          2          2          0          0          0          0\n",
      "                 chair          5          7      0.583      0.286      0.336      0.143\n",
      "         traffic_light          4         11          1          0       0.26      0.161\n",
      "                 truck         27         39      0.407      0.615      0.606       0.41\n",
      "               bollard         14         32      0.457      0.406      0.354      0.206\n",
      "Speed: 0.7ms preprocess, 31.5ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train5\u001b[0m\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.64      0.246      0.278      0.157\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261       0.66      0.826      0.859      0.631\n",
      "          potted_plant          9         26        0.3      0.192      0.204      0.105\n",
      "          fire_hydrant          3          4          1          0     0.0198    0.00593\n",
      "       movable_signage         14         27      0.355       0.37      0.329      0.201\n",
      "            motorcycle          4          4      0.561        0.5      0.423      0.227\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0      0.074     0.0474\n",
      "               bicycle          4          7      0.586      0.611      0.561      0.235\n",
      "          traffic_sign         16         27      0.434      0.111      0.192      0.104\n",
      "             barricade          2          2          1          0      0.166     0.0871\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0      0.181      0.134\n",
      "            tree_trunk         34        121      0.528      0.479      0.475      0.241\n",
      "                person         33         65      0.612      0.446      0.481      0.248\n",
      "                  pole         70        145      0.588      0.566      0.586      0.266\n",
      "                  stop          2          2          0          0          0          0\n",
      "                 chair          5          7      0.583      0.286      0.336      0.143\n",
      "         traffic_light          4         11          1          0       0.26      0.161\n",
      "                 truck         27         39      0.407      0.615      0.606       0.41\n",
      "               bollard         14         32      0.457      0.406      0.354      0.206\n",
      "Speed: 1.2ms preprocess, 28.9ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train52\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_size</td><td>▁</td></tr><tr><td>val_fitness</td><td>▁</td></tr><tr><td>val_map</td><td>▁</td></tr><tr><td>val_map50</td><td>▁</td></tr><tr><td>val_map50_95</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_path</td><td>yolo11_quantized.pt</td></tr><tr><td>quantized_model_size</td><td>2586832</td></tr><tr><td>val_fitness</td><td>0.16898</td></tr><tr><td>val_map</td><td>0.15691</td></tr><tr><td>val_map50</td><td>0.2776</td></tr><tr><td>val_map50_95</td><td>0.15691</td></tr><tr><td>val_precision</td><td>0.63953</td></tr><tr><td>val_recall</td><td>0.24589</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-8</strong> at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/31chi6bc' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/31chi6bc</a><br/> View project at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241031_210745-31chi6bc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: ab93cc8w with config:\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tlearning_rate: 0.0087189110636855\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\희정\\NIPAPROJECT\\wandb\\run-20241031_224829-ab93cc8w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/ab93cc8w' target=\"_blank\">solar-sweep-9</a></strong> to <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/ab93cc8w' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/ab93cc8w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.26 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:/Users//NIPAPROJECT/yolodata/yolo_split/yolo.yaml, epochs=10, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train6\n",
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    435352  ultralytics.nn.modules.head.Detect           [24, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,594,520 parameters, 2,594,504 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train6', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\train\\MP_SEL_000231.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train6\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000357, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.703      4.577      1.314        128        640: 100%|██████████| 24/24 [03:12<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.709      3.793      1.282        166        640: 100%|██████████| 24/24 [03:07<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0467     0.0444     0.0417     0.0318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.648      3.076      1.258        124        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0416      0.111     0.0672     0.0429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.614      2.632      1.238        155        640: 100%|██████████| 24/24 [03:06<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.925     0.0422     0.0983     0.0555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.579      2.339      1.225        126        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.696      0.116       0.14     0.0766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.542      2.154      1.212        140        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.652      0.152      0.145     0.0798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      1.517      1.995      1.207        128        640: 100%|██████████| 24/24 [03:08<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.625      0.152      0.155      0.087\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G      1.484      1.917      1.182        154        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.685      0.177      0.176      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G      1.461      1.862      1.175        127        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.725      0.168      0.176     0.0989\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      1.425       1.81      1.163        191        640: 100%|██████████| 24/24 [03:06<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.733      0.168      0.184      0.105\n",
      "\n",
      "10 epochs completed in 0.540 hours.\n",
      "Optimizer stripped from runs\\detect\\train6\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train6\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train6\\weights\\best.pt...\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.733      0.168      0.184      0.105\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.709      0.786      0.815      0.578\n",
      "          potted_plant          9         26      0.303      0.217      0.185     0.0527\n",
      "          fire_hydrant          3          4          1          0    0.00668    0.00535\n",
      "       movable_signage         14         27      0.681      0.222      0.258      0.195\n",
      "            motorcycle          4          4          1          0      0.124     0.0548\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0     0.0108    0.00492\n",
      "               bicycle          4          7      0.713      0.429       0.52       0.23\n",
      "          traffic_sign         16         27       0.64     0.0741     0.0947     0.0674\n",
      "             barricade          2          2          1          0          0          0\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121      0.543      0.322      0.377      0.169\n",
      "                person         33         65      0.623       0.28      0.359      0.179\n",
      "                  pole         70        145      0.559      0.379      0.453      0.202\n",
      "                  stop          2          2          1          0          0          0\n",
      "                 chair          5          7       0.45      0.143     0.0987     0.0728\n",
      "         traffic_light          4         11          1          0    0.00392    0.00274\n",
      "                 truck         27         39      0.486      0.436      0.442      0.321\n",
      "               bollard         14         32      0.421      0.406      0.307      0.171\n",
      "Speed: 0.7ms preprocess, 32.0ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train6\u001b[0m\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.733      0.168      0.184      0.105\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.709      0.786      0.815      0.578\n",
      "          potted_plant          9         26      0.303      0.217      0.185     0.0527\n",
      "          fire_hydrant          3          4          1          0    0.00668    0.00535\n",
      "       movable_signage         14         27      0.681      0.222      0.258      0.195\n",
      "            motorcycle          4          4          1          0      0.124     0.0548\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0     0.0108    0.00492\n",
      "               bicycle          4          7      0.713      0.429       0.52       0.23\n",
      "          traffic_sign         16         27       0.64     0.0741     0.0947     0.0674\n",
      "             barricade          2          2          1          0          0          0\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121      0.543      0.322      0.377      0.169\n",
      "                person         33         65      0.623       0.28      0.359      0.179\n",
      "                  pole         70        145      0.559      0.379      0.453      0.202\n",
      "                  stop          2          2          1          0          0          0\n",
      "                 chair          5          7       0.45      0.143     0.0987     0.0728\n",
      "         traffic_light          4         11          1          0    0.00392    0.00274\n",
      "                 truck         27         39      0.486      0.436      0.442      0.321\n",
      "               bollard         14         32      0.421      0.406      0.307      0.171\n",
      "Speed: 1.3ms preprocess, 28.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train62\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_size</td><td>▁</td></tr><tr><td>val_fitness</td><td>▁</td></tr><tr><td>val_map</td><td>▁</td></tr><tr><td>val_map50</td><td>▁</td></tr><tr><td>val_map50_95</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_path</td><td>yolo11_quantized.pt</td></tr><tr><td>quantized_model_size</td><td>2586832</td></tr><tr><td>val_fitness</td><td>0.11276</td></tr><tr><td>val_map</td><td>0.10481</td></tr><tr><td>val_map50</td><td>0.1843</td></tr><tr><td>val_map50_95</td><td>0.10481</td></tr><tr><td>val_precision</td><td>0.73309</td></tr><tr><td>val_recall</td><td>0.16795</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-9</strong> at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/ab93cc8w' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/ab93cc8w</a><br/> View project at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241031_224829-ab93cc8w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: gi6oaaml with config:\n",
      "wandb: \tbatch_size: 64\n",
      "wandb: \tepochs: 10\n",
      "wandb: \tlearning_rate: 0.00823474768155081\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\희정\\NIPAPROJECT\\wandb\\run-20241031_232122-gi6oaaml</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/gi6oaaml' target=\"_blank\">confused-sweep-10</a></strong> to <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/gi6oaaml' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/gi6oaaml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.26 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:/Users//NIPAPROJECT/yolodata/yolo_split/yolo.yaml, epochs=10, time=None, patience=100, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train7\n",
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    435352  ultralytics.nn.modules.head.Detect           [24, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,594,520 parameters, 2,594,504 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train7', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\train\\MP_SEL_000231.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train7\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000357, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train7\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.712      4.697      1.341        399        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.682      4.411      1.286        446        640: 100%|██████████| 12/12 [03:07<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.689      3.948      1.265        409        640: 100%|██████████| 12/12 [03:07<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0758     0.0235     0.0498     0.0386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G       1.69      3.486      1.253        476        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0466      0.047     0.0436     0.0335\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G      1.627      3.117      1.234        417        640: 100%|██████████| 12/12 [03:09<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0516     0.0834     0.0573     0.0402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G      1.595      2.803      1.223        381        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0592      0.137     0.0865     0.0571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G      1.569      2.508       1.21        452        640: 100%|██████████| 12/12 [03:07<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0422      0.194      0.113     0.0656\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G       1.54      2.336      1.191        434        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0269       0.25      0.123     0.0662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G      1.522      2.202      1.189        385        640: 100%|██████████| 12/12 [03:07<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.895     0.0635      0.127     0.0695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G      1.473      2.123       1.17        485        640: 100%|██████████| 12/12 [03:09<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.848      0.101      0.149     0.0799\n",
      "\n",
      "10 epochs completed in 0.546 hours.\n",
      "Optimizer stripped from runs\\detect\\train7\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train7\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train7\\weights\\best.pt...\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.845        0.1      0.149       0.08\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.817      0.702      0.805      0.566\n",
      "          potted_plant          9         26          1          0     0.0967     0.0425\n",
      "          fire_hydrant          3          4          1          0          0          0\n",
      "       movable_signage         14         27      0.493      0.148      0.112     0.0873\n",
      "            motorcycle          4          4          1          0     0.0297     0.0186\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0    0.00558    0.00367\n",
      "               bicycle          4          7          1      0.277      0.519      0.121\n",
      "          traffic_sign         16         27          1          0     0.0153      0.012\n",
      "             barricade          2          2          1          0          0          0\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121      0.837       0.17      0.385      0.179\n",
      "                person         33         65      0.647      0.169      0.311      0.144\n",
      "                  pole         70        145      0.639      0.293      0.395      0.171\n",
      "                  stop          2          2          1          0          0          0\n",
      "                 chair          5          7          1          0     0.0541     0.0419\n",
      "         traffic_light          4         11          1          0          0          0\n",
      "                 truck         27         39      0.732      0.351       0.39      0.278\n",
      "               bollard         14         32      0.425     0.0938      0.159     0.0943\n",
      "Speed: 1.0ms preprocess, 34.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train7\u001b[0m\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.845        0.1      0.149       0.08\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.817      0.702      0.805      0.566\n",
      "          potted_plant          9         26          1          0     0.0967     0.0425\n",
      "          fire_hydrant          3          4          1          0          0          0\n",
      "       movable_signage         14         27      0.493      0.148      0.112     0.0873\n",
      "            motorcycle          4          4          1          0     0.0297     0.0186\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0    0.00558    0.00367\n",
      "               bicycle          4          7          1      0.277      0.519      0.121\n",
      "          traffic_sign         16         27          1          0     0.0153      0.012\n",
      "             barricade          2          2          1          0          0          0\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121      0.837       0.17      0.385      0.179\n",
      "                person         33         65      0.647      0.169      0.311      0.144\n",
      "                  pole         70        145      0.639      0.293      0.395      0.171\n",
      "                  stop          2          2          1          0          0          0\n",
      "                 chair          5          7          1          0     0.0541     0.0419\n",
      "         traffic_light          4         11          1          0          0          0\n",
      "                 truck         27         39      0.732      0.351       0.39      0.278\n",
      "               bollard         14         32      0.425     0.0938      0.159     0.0943\n",
      "Speed: 1.0ms preprocess, 31.9ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train72\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_size</td><td>▁</td></tr><tr><td>val_fitness</td><td>▁</td></tr><tr><td>val_map</td><td>▁</td></tr><tr><td>val_map50</td><td>▁</td></tr><tr><td>val_map50_95</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_path</td><td>yolo11_quantized.pt</td></tr><tr><td>quantized_model_size</td><td>2586832</td></tr><tr><td>val_fitness</td><td>0.08687</td></tr><tr><td>val_map</td><td>0.07997</td></tr><tr><td>val_map50</td><td>0.14898</td></tr><tr><td>val_map50_95</td><td>0.07997</td></tr><tr><td>val_precision</td><td>0.84505</td></tr><tr><td>val_recall</td><td>0.10022</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-sweep-10</strong> at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/gi6oaaml' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/gi6oaaml</a><br/> View project at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241031_232122-gi6oaaml\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: prr3wtal with config:\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tepochs: 20\n",
      "wandb: \tlearning_rate: 0.009791708219625297\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\희정\\NIPAPROJECT\\wandb\\run-20241031_235442-prr3wtal</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/prr3wtal' target=\"_blank\">hearty-sweep-11</a></strong> to <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/prr3wtal' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/prr3wtal</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.26 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:/Users//NIPAPROJECT/yolodata/yolo_split/yolo.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train8, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train8\n",
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    435352  ultralytics.nn.modules.head.Detect           [24, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,594,520 parameters, 2,594,504 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train8', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\train\\MP_SEL_000231.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train8\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000357, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train8\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G      1.693      4.418      1.275        369        640: 100%|██████████| 47/47 [03:02<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0685     0.0204     0.0442     0.0376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G      1.707      3.593      1.249        291        640: 100%|██████████| 47/47 [03:01<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0274      0.107     0.0619       0.04\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G      1.673      2.891      1.236        269        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.825      0.078     0.0828     0.0475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G      1.643      2.441       1.24        253        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.725      0.106      0.119     0.0695\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G      1.572       2.13      1.213        275        640: 100%|██████████| 47/47 [03:02<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.734      0.127      0.122     0.0707\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G      1.537       1.95      1.208        272        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.563      0.163      0.143     0.0834\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G      1.516      1.849      1.193        463        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.655      0.164      0.161     0.0927\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G      1.504      1.771      1.177        285        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.608      0.193      0.174      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G      1.478       1.73      1.172        208        640: 100%|██████████| 47/47 [03:01<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.664       0.16      0.176     0.0965\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G      1.447      1.655      1.162        322        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.579      0.175      0.187      0.106\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20         0G       1.46      1.825      1.172        146        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.479      0.175      0.177     0.0969\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G      1.414      1.694      1.164        156        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.591      0.187      0.202      0.115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20         0G      1.398      1.659      1.154        136        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.601      0.184      0.209      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20         0G      1.375      1.609      1.137        104        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.619      0.206      0.213      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20         0G      1.365      1.583      1.136        176        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.626      0.195      0.218      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20         0G      1.354      1.561      1.119        155        640: 100%|██████████| 47/47 [02:54<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.541      0.214      0.237      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20         0G      1.355      1.542      1.124        123        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.612      0.182      0.223      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20         0G      1.323      1.512      1.117        151        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.563      0.216      0.226      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20         0G      1.317        1.5      1.107        132        640: 100%|██████████| 47/47 [02:54<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.629      0.187       0.23      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20         0G      1.317      1.493      1.108        132        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.63      0.185      0.229      0.132\n",
      "\n",
      "20 epochs completed in 1.027 hours.\n",
      "Optimizer stripped from runs\\detect\\train8\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train8\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train8\\weights\\best.pt...\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.541      0.214      0.237      0.132\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.646      0.845      0.839      0.605\n",
      "          potted_plant          9         26      0.314      0.308      0.229     0.0968\n",
      "          fire_hydrant          3          4          1          0     0.0359     0.0241\n",
      "       movable_signage         14         27      0.387      0.296      0.279      0.188\n",
      "            motorcycle          4          4      0.449       0.25      0.291       0.15\n",
      "              stroller          2          2          0          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0     0.0547     0.0244\n",
      "               bicycle          4          7      0.555      0.712      0.629      0.295\n",
      "          traffic_sign         16         27      0.653      0.111      0.163      0.084\n",
      "             barricade          2          2          1          0     0.0216    0.00216\n",
      "               carrier          2          2          0          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121      0.554       0.38      0.447      0.221\n",
      "                person         33         65      0.706      0.296      0.434      0.236\n",
      "                  pole         70        145      0.606      0.462      0.537      0.261\n",
      "                  stop          2          2          0          0          0          0\n",
      "                 chair          5          7      0.122      0.143      0.199       0.09\n",
      "         traffic_light          4         11          1          0      0.134     0.0884\n",
      "                 truck         27         39      0.516      0.465      0.482      0.287\n",
      "               bollard         14         32      0.391      0.438      0.429      0.255\n",
      "Speed: 0.7ms preprocess, 29.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train8\u001b[0m\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.541      0.214      0.237      0.132\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.646      0.845      0.839      0.605\n",
      "          potted_plant          9         26      0.314      0.308      0.229     0.0968\n",
      "          fire_hydrant          3          4          1          0     0.0359     0.0241\n",
      "       movable_signage         14         27      0.387      0.296      0.279      0.188\n",
      "            motorcycle          4          4      0.449       0.25      0.291       0.15\n",
      "              stroller          2          2          0          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0     0.0547     0.0244\n",
      "               bicycle          4          7      0.555      0.712      0.629      0.295\n",
      "          traffic_sign         16         27      0.653      0.111      0.163      0.084\n",
      "             barricade          2          2          1          0     0.0216    0.00216\n",
      "               carrier          2          2          0          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121      0.554       0.38      0.447      0.221\n",
      "                person         33         65      0.706      0.296      0.434      0.236\n",
      "                  pole         70        145      0.606      0.462      0.537      0.261\n",
      "                  stop          2          2          0          0          0          0\n",
      "                 chair          5          7      0.122      0.143      0.199       0.09\n",
      "         traffic_light          4         11          1          0      0.134     0.0884\n",
      "                 truck         27         39      0.516      0.465      0.482      0.287\n",
      "               bollard         14         32      0.391      0.438      0.429      0.255\n",
      "Speed: 0.7ms preprocess, 28.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train82\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_size</td><td>▁</td></tr><tr><td>val_fitness</td><td>▁</td></tr><tr><td>val_map</td><td>▁</td></tr><tr><td>val_map50</td><td>▁</td></tr><tr><td>val_map50_95</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_path</td><td>yolo11_quantized.pt</td></tr><tr><td>quantized_model_size</td><td>2586832</td></tr><tr><td>val_fitness</td><td>0.14256</td></tr><tr><td>val_map</td><td>0.13212</td></tr><tr><td>val_map50</td><td>0.23658</td></tr><tr><td>val_map50_95</td><td>0.13212</td></tr><tr><td>val_precision</td><td>0.54082</td></tr><tr><td>val_recall</td><td>0.21391</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hearty-sweep-11</strong> at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/prr3wtal' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/prr3wtal</a><br/> View project at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241031_235442-prr3wtal\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: ym4sserl with config:\n",
      "wandb: \tbatch_size: 64\n",
      "wandb: \tepochs: 40\n",
      "wandb: \tlearning_rate: 0.0014164564427400317\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\희정\\NIPAPROJECT\\wandb\\run-20241101_005649-ym4sserl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/ym4sserl' target=\"_blank\">spring-sweep-12</a></strong> to <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/ym4sserl' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/ym4sserl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.26 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:/Users//NIPAPROJECT/yolodata/yolo_split/yolo.yaml, epochs=40, time=None, patience=100, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train9, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train9\n",
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    435352  ultralytics.nn.modules.head.Detect           [24, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,594,520 parameters, 2,594,504 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train9', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\train\\MP_SEL_000231.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train9\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000357, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train9\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40         0G       1.68      4.649      1.308        836        640: 100%|██████████| 12/12 [03:18<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40         0G      1.662       4.38      1.245        895        640: 100%|██████████| 12/12 [03:12<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0455   0.000174     0.0228     0.0228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40         0G      1.682      3.952      1.233        826        640: 100%|██████████| 12/12 [03:11<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801        0.1     0.0269     0.0634     0.0513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40         0G      1.674       3.55      1.225        768        640: 100%|██████████| 12/12 [03:11<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0535     0.0517     0.0524     0.0374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40         0G      1.647      3.061      1.209        807        640: 100%|██████████| 12/12 [03:12<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0672     0.0708      0.067     0.0466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40         0G        1.6       2.59      1.213        753        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0732      0.136      0.113     0.0687\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40         0G      1.585      2.305      1.201        889        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0406      0.207       0.11     0.0674\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40         0G      1.542      2.034      1.186        778        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.883     0.0487      0.123     0.0674\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40         0G      1.494      1.879      1.178        730        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.759     0.0757      0.134     0.0728\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40         0G       1.49      1.792       1.18        711        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.695      0.118      0.148     0.0837\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40         0G      1.488       1.74      1.171        733        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.656      0.137      0.164     0.0912\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40         0G      1.464      1.659      1.167        747        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.672      0.142      0.168     0.0944\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40         0G       1.43        1.6       1.15        659        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.61      0.164      0.171     0.0978\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40         0G      1.404      1.567      1.132        726        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.647      0.146      0.177      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40         0G      1.419      1.557      1.132        883        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.624      0.164      0.198      0.114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40         0G      1.389      1.502      1.124        778        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.695      0.164      0.203       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40         0G      1.381       1.47       1.13        926        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.629      0.177      0.201      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40         0G       1.37      1.468      1.116        755        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.687       0.17      0.204      0.114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40         0G      1.341      1.404      1.115        733        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.539      0.204      0.228      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40         0G      1.333       1.38      1.102        776        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.771       0.18      0.222      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40         0G      1.358        1.4      1.117        855        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.667      0.189      0.238       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/40         0G      1.329      1.352       1.09        816        640: 100%|██████████| 12/12 [03:15<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.65      0.196       0.23      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/40         0G      1.318      1.354      1.097        925        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.53      0.215      0.219       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/40         0G      1.327      1.348      1.092        805        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.662      0.197      0.229      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/40         0G      1.314      1.337      1.089        785        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.611      0.223      0.268      0.154\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/40         0G      1.331      1.314      1.095        871        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.703      0.194      0.266      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/40         0G      1.266      1.266      1.076        733        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.763      0.188      0.269      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/40         0G      1.287      1.274      1.067        916        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.75      0.197      0.264      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/40         0G      1.255      1.252       1.06        891        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.68      0.193      0.239      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/40         0G      1.258      1.242      1.065        820        640: 100%|██████████| 12/12 [03:15<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.647      0.185      0.253       0.14\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/40         0G      1.293      1.454      1.098        421        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.462      0.305      0.294      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/40         0G      1.261      1.341      1.076        479        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.775      0.205      0.276      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/40         0G       1.23      1.305      1.069        417        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.57      0.235      0.282      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/40         0G      1.245      1.294      1.072        424        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.526      0.233      0.285      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/40         0G       1.22      1.274       1.06        415        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.704      0.239      0.288      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/40         0G      1.208      1.261      1.052        420        640: 100%|██████████| 12/12 [03:09<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.636      0.232      0.289      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/40         0G      1.205      1.245      1.046        471        640: 100%|██████████| 12/12 [03:09<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.557      0.252      0.293       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/40         0G      1.196      1.241      1.049        470        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.63       0.22      0.291       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/40         0G      1.197      1.225      1.042        370        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.659      0.239      0.298      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/40         0G      1.189      1.232      1.033        357        640: 100%|██████████| 12/12 [03:09<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.642      0.236      0.298      0.171\n",
      "\n",
      "40 epochs completed in 2.221 hours.\n",
      "Optimizer stripped from runs\\detect\\train9\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train9\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train9\\weights\\best.pt...\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.659      0.239      0.297      0.174\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.743      0.816      0.871      0.631\n",
      "          potted_plant          9         26      0.687      0.231      0.296       0.13\n",
      "          fire_hydrant          3          4          1          0     0.0529     0.0272\n",
      "       movable_signage         14         27       0.45       0.37      0.377       0.22\n",
      "            motorcycle          4          4      0.591        0.5      0.423      0.215\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          0          0          0          0\n",
      "                   bus          7          9      0.414     0.0919       0.14     0.0695\n",
      "               bicycle          4          7      0.658      0.552      0.612      0.329\n",
      "          traffic_sign         16         27      0.895      0.148      0.242      0.137\n",
      "             barricade          2          2          1          0      0.199       0.12\n",
      "               carrier          2          2          0          0          0          0\n",
      "                 kiosk          3          4          1          0      0.249      0.224\n",
      "            tree_trunk         34        121      0.577      0.446      0.475      0.221\n",
      "                person         33         65      0.758      0.415      0.531      0.294\n",
      "                  pole         70        145      0.718      0.474      0.572       0.28\n",
      "                  stop          2          2          1          0          0          0\n",
      "                 chair          5          7      0.233      0.143      0.202       0.11\n",
      "         traffic_light          4         11      0.473      0.086      0.231      0.152\n",
      "                 truck         27         39      0.686      0.564      0.615      0.389\n",
      "               bollard         14         32      0.623      0.414      0.452      0.272\n",
      "Speed: 1.0ms preprocess, 34.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train9\u001b[0m\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.659      0.239      0.297      0.174\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.743      0.816      0.871      0.631\n",
      "          potted_plant          9         26      0.687      0.231      0.296       0.13\n",
      "          fire_hydrant          3          4          1          0     0.0529     0.0272\n",
      "       movable_signage         14         27       0.45       0.37      0.377       0.22\n",
      "            motorcycle          4          4      0.591        0.5      0.423      0.215\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          0          0          0          0\n",
      "                   bus          7          9      0.414     0.0919       0.14     0.0695\n",
      "               bicycle          4          7      0.658      0.552      0.612      0.329\n",
      "          traffic_sign         16         27      0.895      0.148      0.242      0.137\n",
      "             barricade          2          2          1          0      0.199       0.12\n",
      "               carrier          2          2          0          0          0          0\n",
      "                 kiosk          3          4          1          0      0.249      0.224\n",
      "            tree_trunk         34        121      0.577      0.446      0.475      0.221\n",
      "                person         33         65      0.758      0.415      0.531      0.294\n",
      "                  pole         70        145      0.718      0.474      0.572       0.28\n",
      "                  stop          2          2          1          0          0          0\n",
      "                 chair          5          7      0.233      0.143      0.202       0.11\n",
      "         traffic_light          4         11      0.473      0.086      0.231      0.152\n",
      "                 truck         27         39      0.686      0.564      0.615      0.389\n",
      "               bollard         14         32      0.623      0.414      0.452      0.272\n",
      "Speed: 0.9ms preprocess, 31.4ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train92\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_size</td><td>▁</td></tr><tr><td>val_fitness</td><td>▁</td></tr><tr><td>val_map</td><td>▁</td></tr><tr><td>val_map50</td><td>▁</td></tr><tr><td>val_map50_95</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_path</td><td>yolo11_quantized.pt</td></tr><tr><td>quantized_model_size</td><td>2586832</td></tr><tr><td>val_fitness</td><td>0.1861</td></tr><tr><td>val_map</td><td>0.17376</td></tr><tr><td>val_map50</td><td>0.29724</td></tr><tr><td>val_map50_95</td><td>0.17376</td></tr><tr><td>val_precision</td><td>0.65928</td></tr><tr><td>val_recall</td><td>0.23872</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">spring-sweep-12</strong> at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/ym4sserl' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/ym4sserl</a><br/> View project at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241101_005649-ym4sserl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: 04ikvekv with config:\n",
      "wandb: \tbatch_size: 32\n",
      "wandb: \tepochs: 20\n",
      "wandb: \tlearning_rate: 0.004947164914886888\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\희정\\NIPAPROJECT\\wandb\\run-20241101_031041-04ikvekv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/04ikvekv' target=\"_blank\">eager-sweep-13</a></strong> to <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/04ikvekv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/04ikvekv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.26 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:/Users//NIPAPROJECT/yolodata/yolo_split/yolo.yaml, epochs=20, time=None, patience=100, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train10\n",
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    435352  ultralytics.nn.modules.head.Detect           [24, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,594,520 parameters, 2,594,504 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train10', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\train\\MP_SEL_000231.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train10\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000357, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train10\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G       1.67      4.539      1.284        365        640: 100%|██████████| 24/24 [03:12<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G      1.711      3.853      1.244        328        640: 100%|██████████| 24/24 [03:12<00:00,  8.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.042     0.0506     0.0428     0.0314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G      1.683      3.156       1.24        253        640: 100%|██████████| 24/24 [03:11<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0504      0.118     0.0724     0.0473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G       1.64      2.705      1.231        269        640: 100%|██████████| 24/24 [03:10<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0264      0.213     0.0988     0.0578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G      1.583      2.253      1.207        320        640: 100%|██████████| 24/24 [03:11<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.741      0.079      0.107     0.0625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G      1.534      2.006      1.206        244        640: 100%|██████████| 24/24 [03:11<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.65       0.11      0.124     0.0735\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G      1.535      1.873      1.197        386        640: 100%|██████████| 24/24 [03:11<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.618       0.14      0.137     0.0805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G      1.461      1.742      1.162        274        640: 100%|██████████| 24/24 [03:10<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.715       0.16      0.173      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G      1.474      1.737      1.174        234        640: 100%|██████████| 24/24 [03:10<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.678      0.163      0.176      0.101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G      1.446      1.654      1.158        242        640: 100%|██████████| 24/24 [03:11<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.528      0.188      0.187      0.107\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20         0G       1.46      1.816      1.178        133        640: 100%|██████████| 24/24 [03:06<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.65      0.161       0.18      0.101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G      1.404      1.668      1.151        165        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.625      0.162      0.197      0.103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20         0G       1.39      1.651      1.144        120        640: 100%|██████████| 24/24 [03:06<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.551      0.193       0.21      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20         0G      1.388      1.619      1.141        139        640: 100%|██████████| 24/24 [03:06<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.625        0.2      0.227      0.124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20         0G       1.37      1.572      1.135        140        640: 100%|██████████| 24/24 [03:06<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.692      0.174      0.222      0.123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20         0G      1.354      1.549      1.122        140        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.634      0.196      0.237      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20         0G      1.342      1.528       1.12        147        640: 100%|██████████| 24/24 [03:06<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.589      0.198      0.229       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20         0G      1.328      1.506      1.117        130        640: 100%|██████████| 24/24 [03:06<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.538      0.198      0.223      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20         0G      1.331      1.506      1.108        149        640: 100%|██████████| 24/24 [03:05<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.57      0.205      0.231      0.137\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20         0G       1.29      1.476      1.097        142        640: 100%|██████████| 24/24 [03:06<00:00,  7.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.558      0.222      0.233      0.136\n",
      "\n",
      "20 epochs completed in 1.089 hours.\n",
      "Optimizer stripped from runs\\detect\\train10\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train10\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train10\\weights\\best.pt...\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.569      0.206      0.231      0.137\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.671      0.812      0.839      0.617\n",
      "          potted_plant          9         26      0.387      0.192      0.203      0.116\n",
      "          fire_hydrant          3          4          1          0     0.0582     0.0306\n",
      "       movable_signage         14         27      0.406      0.259      0.279      0.195\n",
      "            motorcycle          4          4      0.276       0.25      0.209     0.0737\n",
      "              stroller          2          2          0          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0     0.0376     0.0238\n",
      "               bicycle          4          7      0.419      0.429      0.534      0.275\n",
      "          traffic_sign         16         27      0.373     0.0741      0.141     0.0803\n",
      "             barricade          2          2          1          0    0.00507    0.00203\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121      0.506      0.406      0.459      0.224\n",
      "                person         33         65      0.687      0.431      0.477      0.255\n",
      "                  pole         70        145      0.685      0.451      0.529      0.265\n",
      "                  stop          2          2          0          0          0          0\n",
      "                 chair          5          7      0.247      0.143       0.18      0.123\n",
      "         traffic_light          4         11       0.85     0.0909        0.2      0.146\n",
      "                 truck         27         39      0.544      0.564      0.508      0.348\n",
      "               bollard         14         32      0.458      0.422      0.423      0.236\n",
      "Speed: 0.7ms preprocess, 31.9ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train10\u001b[0m\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.569      0.206      0.231      0.137\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.671      0.812      0.839      0.617\n",
      "          potted_plant          9         26      0.387      0.192      0.203      0.116\n",
      "          fire_hydrant          3          4          1          0     0.0582     0.0306\n",
      "       movable_signage         14         27      0.406      0.259      0.279      0.195\n",
      "            motorcycle          4          4      0.276       0.25      0.209     0.0737\n",
      "              stroller          2          2          0          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0     0.0376     0.0238\n",
      "               bicycle          4          7      0.419      0.429      0.534      0.275\n",
      "          traffic_sign         16         27      0.373     0.0741      0.141     0.0803\n",
      "             barricade          2          2          1          0    0.00507    0.00203\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121      0.506      0.406      0.459      0.224\n",
      "                person         33         65      0.687      0.431      0.477      0.255\n",
      "                  pole         70        145      0.685      0.451      0.529      0.265\n",
      "                  stop          2          2          0          0          0          0\n",
      "                 chair          5          7      0.247      0.143       0.18      0.123\n",
      "         traffic_light          4         11       0.85     0.0909        0.2      0.146\n",
      "                 truck         27         39      0.544      0.564      0.508      0.348\n",
      "               bollard         14         32      0.458      0.422      0.423      0.236\n",
      "Speed: 1.2ms preprocess, 29.2ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train102\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_size</td><td>▁</td></tr><tr><td>val_fitness</td><td>▁</td></tr><tr><td>val_map</td><td>▁</td></tr><tr><td>val_map50</td><td>▁</td></tr><tr><td>val_map50_95</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_path</td><td>yolo11_quantized.pt</td></tr><tr><td>quantized_model_size</td><td>2586832</td></tr><tr><td>val_fitness</td><td>0.14624</td></tr><tr><td>val_map</td><td>0.13683</td></tr><tr><td>val_map50</td><td>0.23093</td></tr><tr><td>val_map50_95</td><td>0.13683</td></tr><tr><td>val_precision</td><td>0.56862</td></tr><tr><td>val_recall</td><td>0.20565</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-sweep-13</strong> at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/04ikvekv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/04ikvekv</a><br/> View project at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241101_031041-04ikvekv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: jfh0bwxi with config:\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tepochs: 40\n",
      "wandb: \tlearning_rate: 0.004763741634387627\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\희정\\NIPAPROJECT\\wandb\\run-20241101_041630-jfh0bwxi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/jfh0bwxi' target=\"_blank\">light-sweep-14</a></strong> to <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/jfh0bwxi' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/jfh0bwxi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.26 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:/Users//NIPAPROJECT/yolodata/yolo_split/yolo.yaml, epochs=40, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train11\n",
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    435352  ultralytics.nn.modules.head.Detect           [24, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,594,520 parameters, 2,594,504 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train11', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\train\\MP_SEL_000231.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train11\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000357, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train11\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40         0G      1.693      4.418      1.275        369        640: 100%|██████████| 47/47 [03:02<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0685     0.0204     0.0442     0.0376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40         0G       1.71      3.584       1.25        291        640: 100%|██████████| 47/47 [03:02<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0272        0.1     0.0583     0.0368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40         0G      1.671      2.868      1.238        269        640: 100%|██████████| 47/47 [03:01<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.832      0.085     0.0924     0.0555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40         0G      1.644      2.419      1.242        253        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801        0.7      0.134      0.129     0.0712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40         0G       1.58       2.09      1.217        275        640: 100%|██████████| 47/47 [02:57<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.759       0.13      0.131     0.0723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40         0G      1.558      1.942      1.218        272        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.598      0.138      0.149     0.0849\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40         0G       1.53      1.837      1.197        463        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.622       0.16      0.153     0.0917\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40         0G      1.489      1.758      1.176        285        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.578      0.179      0.186      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40         0G      1.501      1.737      1.182        208        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.531      0.157      0.179      0.101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40         0G      1.461       1.65      1.172        322        640: 100%|██████████| 47/47 [03:01<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.432      0.183      0.189      0.106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40         0G      1.431       1.61      1.154        302        640: 100%|██████████| 47/47 [03:01<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.585      0.178      0.195      0.115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40         0G      1.451      1.586      1.152        250        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.471      0.186      0.193       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40         0G       1.44      1.565      1.149        267        640: 100%|██████████| 47/47 [03:01<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.69       0.16      0.207      0.119\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40         0G      1.408      1.505       1.14        300        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.498      0.195      0.205      0.111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40         0G      1.407      1.507      1.135        217        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.511      0.188      0.209      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40         0G      1.394      1.464       1.13        295        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.632      0.189      0.228      0.128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40         0G      1.366      1.441      1.131        312        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.577      0.214      0.234      0.125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40         0G      1.363      1.437      1.116        280        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.527      0.219      0.242      0.132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40         0G      1.339      1.394      1.114        361        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.676      0.185      0.242      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40         0G      1.341      1.377      1.117        271        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.611      0.208      0.253      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40         0G       1.35      1.372      1.107        280        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.482      0.266      0.254      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/40         0G      1.321      1.348      1.096        242        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.53      0.245       0.28       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/40         0G      1.318      1.346      1.091        253        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.506      0.255      0.266      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/40         0G      1.322      1.317      1.094        278        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.639      0.228       0.29       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/40         0G      1.302      1.319      1.094        173        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.449      0.261      0.275      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/40         0G      1.302      1.293      1.082        180        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.616      0.206      0.256       0.15\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/40         0G      1.283      1.283      1.083        270        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.684      0.236      0.278      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/40         0G      1.307      1.277      1.079        238        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.52       0.25      0.272      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/40         0G      1.279       1.26      1.072        357        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.522      0.245       0.27      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/40         0G      1.271      1.256      1.071        184        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.697      0.221      0.283      0.159\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/40         0G      1.315       1.45      1.105        172        640: 100%|██████████| 47/47 [02:54<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.379      0.245      0.261      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/40         0G      1.272      1.333      1.089        164        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.456      0.277      0.297      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/40         0G      1.268      1.307      1.084        185        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.614      0.253      0.289      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/40         0G      1.258      1.291      1.077        178        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.516      0.256       0.29      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/40         0G       1.23      1.261      1.064        156        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.617      0.248      0.291      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/40         0G      1.214      1.248       1.06        165        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.639      0.232      0.285      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/40         0G      1.216      1.245      1.059        139        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.607      0.251      0.287      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/40         0G       1.22      1.235      1.053        147        640: 100%|██████████| 47/47 [02:56<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.667      0.231       0.29      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/40         0G      1.203      1.218      1.045        148        640: 100%|██████████| 47/47 [02:57<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.705      0.233      0.295      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/40         0G      1.203      1.218      1.051        181        640: 100%|██████████| 47/47 [02:56<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.645      0.263      0.295      0.167\n",
      "\n",
      "40 epochs completed in 2.068 hours.\n",
      "Optimizer stripped from runs\\detect\\train11\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train11\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train11\\weights\\best.pt...\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.702      0.233      0.295      0.169\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.738      0.812       0.87      0.633\n",
      "          potted_plant          9         26      0.508      0.269      0.294      0.128\n",
      "          fire_hydrant          3          4          1          0     0.0333     0.0185\n",
      "       movable_signage         14         27      0.376      0.333      0.282      0.188\n",
      "            motorcycle          4          4          1      0.466      0.502      0.339\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9      0.261      0.111      0.229       0.12\n",
      "               bicycle          4          7      0.575      0.429      0.554      0.176\n",
      "          traffic_sign         16         27      0.626      0.186       0.24      0.117\n",
      "             barricade          2          2          1          0      0.119     0.0563\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0       0.25      0.225\n",
      "            tree_trunk         34        121      0.633      0.413      0.476      0.229\n",
      "                person         33         65      0.762      0.354      0.513      0.276\n",
      "                  pole         70        145      0.699      0.417      0.547      0.276\n",
      "                  stop          2          2          0          0          0          0\n",
      "                 chair          5          7      0.283      0.143      0.176        0.1\n",
      "         traffic_light          4         11      0.797      0.182      0.343      0.168\n",
      "                 truck         27         39      0.651      0.538      0.585      0.398\n",
      "               bollard         14         32      0.544      0.469       0.47      0.258\n",
      "Speed: 0.7ms preprocess, 29.1ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train11\u001b[0m\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.702      0.233      0.295      0.169\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.738      0.812       0.87      0.633\n",
      "          potted_plant          9         26      0.508      0.269      0.294      0.128\n",
      "          fire_hydrant          3          4          1          0     0.0333     0.0185\n",
      "       movable_signage         14         27      0.376      0.333      0.282      0.188\n",
      "            motorcycle          4          4          1      0.466      0.502      0.339\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9      0.261      0.111      0.229       0.12\n",
      "               bicycle          4          7      0.575      0.429      0.554      0.176\n",
      "          traffic_sign         16         27      0.626      0.186       0.24      0.117\n",
      "             barricade          2          2          1          0      0.119     0.0563\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0       0.25      0.225\n",
      "            tree_trunk         34        121      0.633      0.413      0.476      0.229\n",
      "                person         33         65      0.762      0.354      0.513      0.276\n",
      "                  pole         70        145      0.699      0.417      0.547      0.276\n",
      "                  stop          2          2          0          0          0          0\n",
      "                 chair          5          7      0.283      0.143      0.176        0.1\n",
      "         traffic_light          4         11      0.797      0.182      0.343      0.168\n",
      "                 truck         27         39      0.651      0.538      0.585      0.398\n",
      "               bollard         14         32      0.544      0.469       0.47      0.258\n",
      "Speed: 0.7ms preprocess, 28.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train112\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_size</td><td>▁</td></tr><tr><td>val_fitness</td><td>▁</td></tr><tr><td>val_map</td><td>▁</td></tr><tr><td>val_map50</td><td>▁</td></tr><tr><td>val_map50_95</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_path</td><td>yolo11_quantized.pt</td></tr><tr><td>quantized_model_size</td><td>2586832</td></tr><tr><td>val_fitness</td><td>0.18112</td></tr><tr><td>val_map</td><td>0.1685</td></tr><tr><td>val_map50</td><td>0.29464</td></tr><tr><td>val_map50_95</td><td>0.1685</td></tr><tr><td>val_precision</td><td>0.7024</td></tr><tr><td>val_recall</td><td>0.2328</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">light-sweep-14</strong> at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/jfh0bwxi' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/jfh0bwxi</a><br/> View project at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241101_041630-jfh0bwxi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: a7ee6g2v with config:\n",
      "wandb: \tbatch_size: 64\n",
      "wandb: \tepochs: 20\n",
      "wandb: \tlearning_rate: 0.005936611682378658\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\희정\\NIPAPROJECT\\wandb\\run-20241101_062101-a7ee6g2v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/a7ee6g2v' target=\"_blank\">smart-sweep-15</a></strong> to <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/a7ee6g2v' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/a7ee6g2v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.26 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:/Users//NIPAPROJECT/yolodata/yolo_split/yolo.yaml, epochs=20, time=None, patience=100, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train12, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train12\n",
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    435352  ultralytics.nn.modules.head.Detect           [24, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,594,520 parameters, 2,594,504 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train12', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\train\\MP_SEL_000231.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train12\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000357, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train12\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G       1.68      4.649      1.308        836        640: 100%|██████████| 12/12 [03:18<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G      1.662      4.384      1.245        895        640: 100%|██████████| 12/12 [03:12<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0455   0.000174     0.0228     0.0228\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G      1.683      3.969      1.235        826        640: 100%|██████████| 12/12 [03:14<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.103     0.0264     0.0646     0.0514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G      1.668      3.584      1.227        768        640: 100%|██████████| 12/12 [03:11<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0552     0.0509     0.0514      0.038\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G       1.66      3.125      1.216        807        640: 100%|██████████| 12/12 [03:12<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0891     0.0712     0.0791     0.0557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G      1.605      2.666       1.21        753        640: 100%|██████████| 12/12 [03:11<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0863       0.13      0.113     0.0725\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G      1.579      2.394      1.199        889        640: 100%|██████████| 12/12 [03:11<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0452      0.162      0.102     0.0598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G      1.545       2.12      1.185        778        640: 100%|██████████| 12/12 [03:12<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.791     0.0612      0.121     0.0681\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G       1.49      1.936      1.171        730        640: 100%|██████████| 12/12 [03:13<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.711     0.0838      0.152     0.0756\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G      1.484      1.835      1.175        788        640: 100%|██████████| 12/12 [03:15<00:00, 16.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.707      0.113      0.157     0.0932\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20         0G      1.523      1.953      1.204        490        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.592       0.13      0.161     0.0872\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G      1.429      1.781       1.17        444        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.663      0.136      0.174     0.0993\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20         0G      1.433      1.741      1.164        392        640: 100%|██████████| 12/12 [03:09<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.629      0.164       0.18      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20         0G      1.403      1.684      1.149        374        640: 100%|██████████| 12/12 [03:07<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.628      0.157      0.194      0.112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20         0G      1.383      1.646      1.134        415        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.62      0.183      0.201      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20         0G      1.382      1.622      1.139        379        640: 100%|██████████| 12/12 [03:06<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.63      0.201       0.21      0.125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20         0G      1.362      1.598       1.12        406        640: 100%|██████████| 12/12 [03:07<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.606      0.198      0.212       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20         0G      1.353      1.574       1.12        381        640: 100%|██████████| 12/12 [03:07<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.598      0.216      0.215      0.123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20         0G      1.324       1.56      1.114        453        640: 100%|██████████| 12/12 [03:08<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.663      0.202      0.223      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20         0G      1.327      1.544       1.11        448        640: 100%|██████████| 12/12 [03:07<00:00, 15.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.74      0.192       0.23      0.132\n",
      "\n",
      "20 epochs completed in 1.099 hours.\n",
      "Optimizer stripped from runs\\detect\\train12\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train12\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train12\\weights\\best.pt...\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.74      0.192       0.23      0.132\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261       0.72      0.766      0.814      0.594\n",
      "          potted_plant          9         26      0.521      0.192      0.213      0.119\n",
      "          fire_hydrant          3          4          1          0          0          0\n",
      "       movable_signage         14         27      0.628      0.222      0.283      0.191\n",
      "            motorcycle          4          4      0.605       0.25      0.329       0.21\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0     0.0435     0.0147\n",
      "               bicycle          4          7      0.602      0.571      0.509      0.153\n",
      "          traffic_sign         16         27      0.729      0.111      0.123     0.0792\n",
      "             barricade          2          2          1          0          0          0\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121       0.58      0.347      0.443      0.227\n",
      "                person         33         65       0.67      0.354       0.42      0.215\n",
      "                  pole         70        145      0.674      0.386      0.524      0.255\n",
      "                  stop          2          2          1          0          0          0\n",
      "                 chair          5          7      0.467      0.143      0.117     0.0596\n",
      "         traffic_light          4         11          1          0      0.281      0.169\n",
      "                 truck         27         39      0.627      0.473      0.561      0.393\n",
      "               bollard         14         32      0.469      0.406      0.392      0.231\n",
      "Speed: 1.0ms preprocess, 33.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train12\u001b[0m\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.74      0.192       0.23      0.132\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261       0.72      0.766      0.814      0.594\n",
      "          potted_plant          9         26      0.521      0.192      0.213      0.119\n",
      "          fire_hydrant          3          4          1          0          0          0\n",
      "       movable_signage         14         27      0.628      0.222      0.283      0.191\n",
      "            motorcycle          4          4      0.605       0.25      0.329       0.21\n",
      "              stroller          2          2          1          0          0          0\n",
      "                 table          2          2          1          0          0          0\n",
      "                   bus          7          9          0          0     0.0435     0.0147\n",
      "               bicycle          4          7      0.602      0.571      0.509      0.153\n",
      "          traffic_sign         16         27      0.729      0.111      0.123     0.0792\n",
      "             barricade          2          2          1          0          0          0\n",
      "               carrier          2          2          1          0          0          0\n",
      "                 kiosk          3          4          1          0          0          0\n",
      "            tree_trunk         34        121       0.58      0.347      0.443      0.227\n",
      "                person         33         65       0.67      0.354       0.42      0.215\n",
      "                  pole         70        145      0.674      0.386      0.524      0.255\n",
      "                  stop          2          2          1          0          0          0\n",
      "                 chair          5          7      0.467      0.143      0.117     0.0596\n",
      "         traffic_light          4         11          1          0      0.281      0.169\n",
      "                 truck         27         39      0.627      0.473      0.561      0.393\n",
      "               bollard         14         32      0.469      0.406      0.392      0.231\n",
      "Speed: 0.9ms preprocess, 30.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train122\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_size</td><td>▁</td></tr><tr><td>val_fitness</td><td>▁</td></tr><tr><td>val_map</td><td>▁</td></tr><tr><td>val_map50</td><td>▁</td></tr><tr><td>val_map50_95</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_path</td><td>yolo11_quantized.pt</td></tr><tr><td>quantized_model_size</td><td>2586832</td></tr><tr><td>val_fitness</td><td>0.14209</td></tr><tr><td>val_map</td><td>0.13235</td></tr><tr><td>val_map50</td><td>0.22967</td></tr><tr><td>val_map50_95</td><td>0.13235</td></tr><tr><td>val_precision</td><td>0.74044</td></tr><tr><td>val_recall</td><td>0.19195</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smart-sweep-15</strong> at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/a7ee6g2v' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/a7ee6g2v</a><br/> View project at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241101_062101-a7ee6g2v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: zk34kxju with config:\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tepochs: 50\n",
      "wandb: \tlearning_rate: 0.001396492110798156\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\희정\\NIPAPROJECT\\wandb\\run-20241101_072726-zk34kxju</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/zk34kxju' target=\"_blank\">fresh-sweep-16</a></strong> to <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/sweeps/r4oeedyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/zk34kxju' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/zk34kxju</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.26 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:/Users//NIPAPROJECT/yolodata/yolo_split/yolo.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train13, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train13\n",
      "Overriding model.yaml nc=80 with nc=24\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    435352  ultralytics.nn.modules.head.Detect           [24, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,594,520 parameters, 2,594,504 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train13', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\train.cache... 752 images, 0 backgrounds, 0 corrupt: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\\\NIPAPROJECT\\yolodata\\yolo_split\\train\\MP_SEL_000231.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train13\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000357, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train13\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.693      4.418      1.275        369        640: 100%|██████████| 47/47 [03:02<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0685     0.0204     0.0442     0.0376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50         0G      1.709      3.583      1.249        291        640: 100%|██████████| 47/47 [03:01<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801     0.0257      0.117     0.0615     0.0383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50         0G      1.667      2.862      1.238        269        640: 100%|██████████| 47/47 [03:01<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.826     0.0865      0.085     0.0482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50         0G      1.635       2.41      1.244        253        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.635      0.155      0.128     0.0753\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50         0G      1.587      2.105      1.217        275        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.664      0.156      0.127     0.0696\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50         0G      1.564      1.966       1.22        260        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.684      0.161      0.159     0.0889\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50         0G      1.528      1.847      1.199        258        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.657      0.177      0.178      0.101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50         0G      1.488      1.727      1.178        265        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.643      0.169      0.183      0.102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50         0G      1.488      1.698      1.181        238        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.641      0.158      0.178      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50         0G       1.46      1.643      1.168        290        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.647      0.168      0.204      0.116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50         0G      1.439      1.608      1.153        346        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.647       0.18      0.208      0.114\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50         0G      1.451      1.578      1.156        273        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.541      0.197      0.198      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50         0G      1.429      1.548      1.143        302        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.588      0.189      0.208      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50         0G      1.393      1.492      1.143        236        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.607      0.177      0.216      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50         0G      1.405      1.508      1.143        246        640: 100%|██████████| 47/47 [02:58<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.438      0.209      0.226      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50         0G      1.379      1.461      1.134        249        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.551      0.206      0.229      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50         0G      1.362      1.423      1.123        241        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.645      0.194      0.221       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50         0G      1.374      1.439      1.122        260        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.592      0.213      0.251      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50         0G      1.352      1.398      1.123        357        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.543      0.201      0.246      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50         0G      1.339      1.374      1.106        275        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.556      0.212      0.248      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50         0G      1.346      1.384      1.113        256        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.501      0.226      0.264      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50         0G       1.36      1.365      1.108        296        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.528      0.241      0.251      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50         0G      1.323      1.336      1.099        332        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.607      0.225      0.254      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50         0G      1.335      1.342      1.101        232        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.614      0.235      0.278       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50         0G       1.32      1.318      1.097        274        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.568      0.232      0.278      0.149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50         0G      1.338      1.311      1.093        304        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.631      0.217      0.264      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50         0G      1.299      1.275       1.09        270        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.682      0.215      0.282       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50         0G      1.316      1.272      1.084        238        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.601      0.222      0.265      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50         0G      1.286      1.249      1.075        357        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.633      0.227      0.269      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50         0G      1.279      1.256      1.076        184        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.568      0.225      0.293      0.165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50         0G      1.274       1.24      1.072        295        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.545      0.241      0.308      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50         0G      1.283      1.221      1.072        376        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.456       0.29      0.325      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50         0G      1.256      1.204      1.068        193        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.742      0.208      0.298      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50         0G      1.256      1.212      1.063        262        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.498      0.265      0.284      0.152\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50         0G      1.241      1.189      1.065        277        640: 100%|██████████| 47/47 [02:59<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.571      0.232      0.282      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50         0G      1.251      1.177       1.06        255        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.665      0.211      0.296      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50         0G      1.246      1.176      1.057        296        640: 100%|██████████| 47/47 [03:00<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.593      0.237      0.295      0.164\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50         0G       1.24       1.17      1.052        244        640: 100%|██████████| 47/47 [03:07<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.639      0.221      0.292      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50         0G      1.218      1.163      1.045        294        640: 100%|██████████| 47/47 [03:09<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.659      0.233      0.302      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50         0G      1.222      1.172       1.05        265        640: 100%|██████████| 47/47 [03:08<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.655      0.218      0.315      0.193\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50         0G      1.255      1.322      1.077        129        640: 100%|██████████| 47/47 [03:05<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.542      0.258      0.323      0.189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50         0G      1.232      1.239       1.06        113        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.452      0.295      0.323      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50         0G      1.208      1.203      1.055        132        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.556      0.258      0.309      0.183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50         0G      1.208      1.186      1.052        209        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.545      0.267      0.348      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50         0G      1.197      1.183      1.044        151        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801       0.65      0.253      0.349      0.204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50         0G      1.182      1.167      1.047        123        640: 100%|██████████| 47/47 [02:56<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.643      0.256      0.349      0.203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50         0G      1.169      1.145      1.034        163        640: 100%|██████████| 47/47 [02:55<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801        0.6      0.266      0.344      0.202\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50         0G      1.169       1.15       1.03        129        640: 100%|██████████| 47/47 [03:01<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.585      0.264      0.326      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50         0G      1.164      1.152      1.034        142        640: 100%|██████████| 47/47 [03:03<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.625      0.248      0.329      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50         0G      1.162      1.135      1.031        131        640: 100%|██████████| 47/47 [03:02<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:06<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.682      0.241      0.327      0.192\n",
      "\n",
      "50 epochs completed in 2.599 hours.\n",
      "Optimizer stripped from runs\\detect\\train13\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\train13\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\train13\\weights\\best.pt...\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.532      0.291      0.348      0.205\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.664      0.858      0.866      0.626\n",
      "          potted_plant          9         26      0.386      0.308        0.3      0.125\n",
      "          fire_hydrant          3          4          1          0     0.0273     0.0154\n",
      "       movable_signage         14         27      0.343       0.37      0.395      0.239\n",
      "            motorcycle          4          4      0.327       0.25      0.321      0.244\n",
      "              stroller          2          2          1          0     0.0138     0.0124\n",
      "                 table          2          2          0          0     0.0111    0.00221\n",
      "                   bus          7          9      0.278      0.111      0.215      0.109\n",
      "               bicycle          4          7       0.71      0.857      0.795      0.333\n",
      "          traffic_sign         16         27      0.373      0.185      0.235      0.125\n",
      "             barricade          2          2          1          0      0.828      0.514\n",
      "               carrier          2          2          0          0    0.00428   0.000428\n",
      "                 kiosk          3          4          1          0       0.25      0.225\n",
      "            tree_trunk         34        121      0.581      0.496      0.503      0.247\n",
      "                person         33         65      0.564      0.508      0.534      0.296\n",
      "                  pole         70        145      0.562      0.538      0.593      0.288\n",
      "                  stop          2          2          0          0          0          0\n",
      "                 chair          5          7      0.239      0.286      0.284      0.198\n",
      "         traffic_light          4         11      0.623      0.455      0.337      0.193\n",
      "                 truck         27         39      0.601      0.641      0.645      0.437\n",
      "               bollard         14         32      0.462      0.531      0.504       0.29\n",
      "Speed: 0.7ms preprocess, 30.2ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train13\u001b[0m\n",
      "Ultralytics 8.3.25  Python-3.8.19 torch-2.4.1+cpu CPU (Intel Core(TM) i7-10700 2.90GHz)\n",
      "YOLO11n summary (fused): 238 layers, 2,586,832 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████Scanning C:\\Users\\희정\\NIPAPROJECT\\yolodata\\yolo_split\\val.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|████\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        801      0.532      0.291      0.348      0.205\n",
      "                 bench          1          2          1          0          0          0\n",
      "                   car         76        261      0.664      0.858      0.866      0.626\n",
      "          potted_plant          9         26      0.386      0.308        0.3      0.125\n",
      "          fire_hydrant          3          4          1          0     0.0273     0.0154\n",
      "       movable_signage         14         27      0.343       0.37      0.395      0.239\n",
      "            motorcycle          4          4      0.327       0.25      0.321      0.244\n",
      "              stroller          2          2          1          0     0.0138     0.0124\n",
      "                 table          2          2          0          0     0.0111    0.00221\n",
      "                   bus          7          9      0.278      0.111      0.215      0.109\n",
      "               bicycle          4          7       0.71      0.857      0.795      0.333\n",
      "          traffic_sign         16         27      0.373      0.185      0.235      0.125\n",
      "             barricade          2          2          1          0      0.828      0.514\n",
      "               carrier          2          2          0          0    0.00428   0.000428\n",
      "                 kiosk          3          4          1          0       0.25      0.225\n",
      "            tree_trunk         34        121      0.581      0.496      0.503      0.247\n",
      "                person         33         65      0.564      0.508      0.534      0.296\n",
      "                  pole         70        145      0.562      0.538      0.593      0.288\n",
      "                  stop          2          2          0          0          0          0\n",
      "                 chair          5          7      0.239      0.286      0.284      0.198\n",
      "         traffic_light          4         11      0.623      0.455      0.337      0.193\n",
      "                 truck         27         39      0.601      0.641      0.645      0.437\n",
      "               bollard         14         32      0.462      0.531      0.504       0.29\n",
      "Speed: 0.7ms preprocess, 28.7ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train132\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_size</td><td>▁</td></tr><tr><td>val_fitness</td><td>▁</td></tr><tr><td>val_map</td><td>▁</td></tr><tr><td>val_map50</td><td>▁</td></tr><tr><td>val_map50_95</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>quantized_model_path</td><td>yolo11_quantized.pt</td></tr><tr><td>quantized_model_size</td><td>2586832</td></tr><tr><td>val_fitness</td><td>0.21971</td></tr><tr><td>val_map</td><td>0.20543</td></tr><tr><td>val_map50</td><td>0.34825</td></tr><tr><td>val_map50_95</td><td>0.20543</td></tr><tr><td>val_precision</td><td>0.53247</td></tr><tr><td>val_recall</td><td>0.29063</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-16</strong> at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/zk34kxju' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization/runs/zk34kxju</a><br/> View project at: <a href='https://wandb.ai/icejoy000524-student/yolo11-quantization' target=\"_blank\">https://wandb.ai/icejoy000524-student/yolo11-quantization</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241101_072726-zk34kxju\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sweep 에이전트 실행\n",
    "wandb.agent(sweep_id, function=train, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3cac9-1941-49aa-8d43-fe1e771e9c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-gpu",
   "language": "python",
   "name": "python-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
